{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import Tensor\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms\n",
    "\n",
    "composed_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(), # performs scaling by default for image datasets between range(0-1)\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "train_val_set = MNIST(\"./data/train\", train=True, transform=composed_transforms, download=True)\n",
    "test_set = MNIST(\"./data/test\", train=False, transform=composed_transforms, download=True)\n",
    "\n",
    "train_set, val_set = torch.utils.data.random_split(dataset=train_val_set, lengths=[.9, .1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note \n",
    "```\n",
    "If iteration performed over a dataset with transforms, transform operations cen be triggered, if not, will be triggered on train loop and may slow down the process\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28]) 8\n",
      "tensor([-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "        -1.0000, -1.0000, -1.0000, -0.6627, -0.6706, -1.0000, -1.0000, -1.0000,\n",
      "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "        -1.0000, -1.0000, -1.0000, -0.8980, -0.8118, -0.2863,  0.1059,  0.9529,\n",
      "         0.9529,  0.3647, -0.0902,  0.0353,  0.6235,  0.0353, -1.0000, -1.0000,\n",
      "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.7333,  0.4510,  0.7412,\n",
      "         0.9843,  0.9843,  0.9922,  0.9843,  0.9843,  0.9843,  0.7882,  0.2549,\n",
      "         0.2549, -0.1922, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "        -0.8824,  0.7961,  0.9922,  0.9922,  0.9922,  0.9922,  0.9922,  0.9922,\n",
      "         0.9922,  0.9922,  0.8510, -0.8667, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "        -0.9608, -0.6314, -0.6314, -0.4980,  0.1686,  0.9843,  0.9922,  0.9843,\n",
      "         0.9843,  0.9843,  0.9922,  0.9843,  0.9843,  0.7176, -0.6078, -1.0000,\n",
      "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "        -1.0000, -1.0000, -1.0000, -1.0000,  0.3647,  0.9843,  0.9922,  0.9843,\n",
      "         0.9843,  0.9137,  0.6078, -0.0510, -0.6392, -0.6392,  0.4588,  0.9843,\n",
      "         0.9843, -0.1922, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.4667,\n",
      "         0.8824,  0.9843,  0.9922,  0.5843, -0.0667, -0.6549, -1.0000, -1.0000,\n",
      "        -0.6000,  0.4431,  0.9922,  0.9843,  0.0588, -0.8510, -1.0000, -1.0000,\n",
      "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "        -1.0000, -1.0000, -1.0000, -1.0000, -0.0196,  0.9922,  0.9922,  0.8588,\n",
      "        -0.1059, -0.6000, -0.4510,  0.2000,  0.8588,  0.9922,  0.9922,  0.0980,\n",
      "        -0.8667, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "        -0.9765, -0.8196, -0.0980,  0.7569,  0.9686,  0.9373,  0.9922,  0.9843,\n",
      "         0.9843,  0.7176, -0.8196, -0.9843, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "        -1.0000, -1.0000, -1.0000, -1.0000, -0.9137, -0.2863,  0.3647,  0.8196,\n",
      "         0.9843,  0.9843,  0.9922,  0.9843, -0.0824, -0.8980, -1.0000, -1.0000,\n",
      "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.3333,\n",
      "         0.5608,  0.9843,  0.9922,  0.9843,  0.3882,  0.2549,  0.7255,  0.9843,\n",
      "         0.1451, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "        -1.0000, -1.0000,  0.2706,  0.9922,  0.9922,  0.9922, -0.0039, -0.6706,\n",
      "        -1.0000, -1.0000, -0.7961,  0.6784,  0.8588, -0.8510, -1.0000, -1.0000,\n",
      "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  0.9216,  0.9843,\n",
      "         0.2863, -0.8196, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  0.7412,\n",
      "         0.8196, -0.9529, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "        -1.0000, -1.0000,  0.9922,  0.9843, -0.4902, -0.9451, -1.0000, -1.0000,\n",
      "        -1.0000, -1.0000, -0.1529,  0.9529,  0.7333, -1.0000, -1.0000, -1.0000,\n",
      "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  0.1922,  0.9843,\n",
      "         0.9843,  0.5922, -0.0039, -0.2706, -0.2706,  0.2471,  0.9922,  0.9843,\n",
      "        -0.1843, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "        -1.0000, -1.0000, -1.0000,  0.3176,  0.8902,  0.9922,  1.0000,  0.9922,\n",
      "         0.9922,  0.9922,  0.8510, -0.3412, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "        -0.8510, -0.2941,  0.1608,  0.5529,  0.0275, -0.3647, -0.8667, -1.0000,\n",
      "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000])\n"
     ]
    },
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/wAALCAAcABwBAREA/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/9oACAEBAAA/APAKACTgDJNaY8Oa22ntfjSb02qMVaUQtgEJ5nPHTZ82emOaz5YpIJXilRo5EYq6OMFSOoI7GkjCGRBIzLGSNzKu4gdyBkZP4ivpTwx4J0PRbKDXfBum/wDCQ3vkoh+2zeSpz8zNtdMo2FG32kz0wazPiZ8WZbLRrvwxG9pcavKrRXc9oCIbfnBjG7JdsbskY2kjrzXgE9xNdS+bcTSSyYC75GLHAAAGT2AAA9hWz4M1XTtE8Y6XqerWhurG2nDyRDr0OG99pw2O+Md69RbUtNfxZb63qvxPW4sLKfzoLS0jkjcReWgVVULsVidgZAOgc5B3Y8f1q7t7/XdQu7SEQ209xJJDGECbELEqNo4GBjgVRoooor//2Q==",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABHUlEQVR4AWNkZMANmHBLMTAMFsmwEJgrGVGBtOEO6c+fY19xzudkZGRAkXMt3vv799/fv3+fdHS8gCYpf/ovFNxUBmligRnPFcKgvNKA4R/Q6/8Y9qy7BxaHGRsLMu7l7C+xsaW/fwONBAGYnV0Pf/+d+iGSkTG98O9vfnVUScY/f//efpbeZ3z7719JsIVIOhnZ9V8c/P4eaPR2fVaIPoSxjOI7Yi+CvPFGGiaFkFzTD5RIdtz5WxUhB3OQK9B/DKGMjKZrb0MdA1IDde3r3576YC17L/IitEIjW4jB+gHI2zfNXn0Bex9CQNQZ/v49nWHPHvu/vy8hNMKMZQx8/Pc/0N6bq5Dk4JKM6ts0e9mXwLwPU4JkBTpzIFIfAJPVb5nyAAiaAAAAAElFTkSuQmCC",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = iter(train_set).__next__()\n",
    "print(X.shape, y)\n",
    "print(X[X != 0]) # already scaled between 0-1\n",
    "transforms.ToPILImage()(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class LeNet5(nn.Module):\n",
    "    \n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.feature_extractor = nn.Sequential(\n",
    "            # Input -> (batch_size,1,32,32)\n",
    "            # Layer 1\n",
    "            nn.Conv2d(\n",
    "                in_channels=1, \n",
    "                out_channels=6,\n",
    "                kernel_size=5,\n",
    "                padding=2, # padding as 2 for achieving expected size\n",
    "                stride=1), # -> (batch_size,6,28,28)\n",
    "            nn.Tanh(),\n",
    "            nn.AvgPool2d(kernel_size=2, stride=2), # -> (batch_size,6,14,14)\n",
    "            \n",
    "            # Layer 2\n",
    "            nn.Conv2d(\n",
    "                in_channels=6,\n",
    "                out_channels=16,\n",
    "                kernel_size=5,\n",
    "                stride=1,\n",
    "                padding=0), # -> (batch_size,16,10,10)\n",
    "            nn.Tanh(),\n",
    "            nn.AvgPool2d(kernel_size=2, stride=2), # (batch_size,16,5,5)\n",
    "        )\n",
    "        self.fully_connected = nn.Sequential(\n",
    "            nn.Flatten(), # (batch_size,400)\n",
    "            nn.Linear(in_features=400, out_features=120), # (batch_size,120)\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(in_features=120, out_features=84), # (batch_size,84)\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(in_features=84, out_features=10), # (batch_size,10)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.fully_connected(self.feature_extractor(x))\n",
    "    \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LeNet5(\n",
       "  (feature_extractor): Sequential(\n",
       "    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (1): Tanh()\n",
       "    (2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    (3): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (4): Tanh()\n",
       "    (5): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "  )\n",
       "  (fully_connected): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(in_features=400, out_features=120, bias=True)\n",
       "    (2): Tanh()\n",
       "    (3): Linear(in_features=120, out_features=84, bias=True)\n",
       "    (4): Tanh()\n",
       "    (5): Linear(in_features=84, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LeNet5().to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "LeNet5                                   [1, 10]                   --\n",
       "├─Sequential: 1-1                        [1, 16, 5, 5]             --\n",
       "│    └─Conv2d: 2-1                       [1, 6, 28, 28]            156\n",
       "│    └─Tanh: 2-2                         [1, 6, 28, 28]            --\n",
       "│    └─AvgPool2d: 2-3                    [1, 6, 14, 14]            --\n",
       "│    └─Conv2d: 2-4                       [1, 16, 10, 10]           2,416\n",
       "│    └─Tanh: 2-5                         [1, 16, 10, 10]           --\n",
       "│    └─AvgPool2d: 2-6                    [1, 16, 5, 5]             --\n",
       "├─Sequential: 1-2                        [1, 10]                   --\n",
       "│    └─Flatten: 2-7                      [1, 400]                  --\n",
       "│    └─Linear: 2-8                       [1, 120]                  48,120\n",
       "│    └─Tanh: 2-9                         [1, 120]                  --\n",
       "│    └─Linear: 2-10                      [1, 84]                   10,164\n",
       "│    └─Tanh: 2-11                        [1, 84]                   --\n",
       "│    └─Linear: 2-12                      [1, 10]                   850\n",
       "==========================================================================================\n",
       "Total params: 61,706\n",
       "Trainable params: 61,706\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 0.42\n",
       "==========================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 0.05\n",
       "Params size (MB): 0.25\n",
       "Estimated Total Size (MB): 0.30\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "\n",
    "\n",
    "summary(model, input_size=(1,1,28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "learning_rate = 0.001\n",
    "epochs = 10\n",
    "batch_size=16\n",
    "\n",
    "# Should be SGD according to paper\n",
    "optimizer = Adam(params=model.parameters(), lr=learning_rate)\n",
    "criterion =  CrossEntropyLoss()\n",
    "\n",
    "summary_logger = SummaryWriter(\n",
    "    os.path.join(\n",
    "        \"experiments\",\n",
    "        datetime.now().strftime(\"%d.%m.%Y\"),\n",
    "        \"Experiment 1\",\n",
    "        \"LeNet5_01\"\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<torch.utils.data.dataloader.DataLoader at 0x1c55391f750>,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x1c512fe3890>,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x1c512ef49d0>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataloader = DataLoader(\n",
    "    train_set, \n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=8)\n",
    "\n",
    "val_dataloader = DataLoader(\n",
    "    val_set, \n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=8)\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    test_set, \n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=8)\n",
    "\n",
    "train_dataloader, val_dataloader, test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics import Accuracy\n",
    "\n",
    "\n",
    "accuracy = Accuracy(task='multiclass', num_classes=10).to(device)\n",
    "\n",
    "\n",
    "def calculate_accuracy(pred: Tensor, y: Tensor) -> Tensor:\n",
    "    y_pred = nn.functional.softmax(pred, dim=1)\n",
    "    argmax_ = torch.argmax(y_pred, axis=1)\n",
    "    trues = (argmax_ == y).float()\n",
    "    return torch.mean(trues)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3375/3375 [00:41<00:00, 80.46it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 375/375 [00:06<00:00, 58.52it/s] \n",
      " 10%|█         | 1/10 [00:48<07:15, 48.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch: 0 -- Train Loss:  0.201 -- Train Acc :  0.940 -- Val Loss:  0.110 -- Val Acc:  0.967 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3375/3375 [00:40<00:00, 83.10it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 375/375 [00:06<00:00, 57.58it/s] \n",
      " 20%|██        | 2/10 [01:35<06:21, 47.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch: 1 -- Train Loss:  0.080 -- Train Acc :  0.975 -- Val Loss:  0.068 -- Val Acc:  0.979 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3375/3375 [00:40<00:00, 83.83it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 375/375 [00:06<00:00, 57.15it/s] \n",
      " 30%|███       | 3/10 [02:22<05:31, 47.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch: 2 -- Train Loss:  0.060 -- Train Acc :  0.982 -- Val Loss:  0.076 -- Val Acc:  0.975 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3375/3375 [00:40<00:00, 83.04it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 375/375 [00:06<00:00, 57.51it/s] \n",
      " 40%|████      | 4/10 [03:09<04:43, 47.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch: 3 -- Train Loss:  0.049 -- Train Acc :  0.985 -- Val Loss:  0.078 -- Val Acc:  0.975 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3375/3375 [00:40<00:00, 83.11it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 375/375 [00:06<00:00, 57.95it/s] \n",
      " 50%|█████     | 5/10 [03:56<03:56, 47.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch: 4 -- Train Loss:  0.040 -- Train Acc :  0.987 -- Val Loss:  0.074 -- Val Acc:  0.979 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3375/3375 [00:40<00:00, 83.60it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 375/375 [00:06<00:00, 58.25it/s] \n",
      " 60%|██████    | 6/10 [04:43<03:08, 47.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch: 5 -- Train Loss:  0.034 -- Train Acc :  0.989 -- Val Loss:  0.071 -- Val Acc:  0.978 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3375/3375 [00:40<00:00, 83.23it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 375/375 [00:06<00:00, 58.38it/s] \n",
      " 70%|███████   | 7/10 [05:30<02:21, 47.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch: 6 -- Train Loss:  0.031 -- Train Acc :  0.990 -- Val Loss:  0.066 -- Val Acc:  0.979 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3375/3375 [00:40<00:00, 84.20it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 375/375 [00:06<00:00, 58.50it/s] \n",
      " 80%|████████  | 8/10 [06:17<01:33, 46.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch: 7 -- Train Loss:  0.028 -- Train Acc :  0.991 -- Val Loss:  0.066 -- Val Acc:  0.979 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3375/3375 [00:40<00:00, 83.15it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 375/375 [00:06<00:00, 57.94it/s] \n",
      " 90%|█████████ | 9/10 [07:04<00:46, 46.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch: 8 -- Train Loss:  0.025 -- Train Acc :  0.992 -- Val Loss:  0.061 -- Val Acc:  0.982 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3375/3375 [00:40<00:00, 83.06it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 375/375 [00:06<00:00, 58.38it/s] \n",
      "100%|██████████| 10/10 [07:51<00:00, 47.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch: 9 -- Train Loss:  0.023 -- Train Acc :  0.993 -- Val Loss:  0.055 -- Val Acc:  0.984 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm \n",
    "\n",
    "# MNIST well balanced dataset, no need for precision or recall\n",
    "\n",
    "\n",
    "# rain_losses = list()\n",
    "# alidation_losses = list()\n",
    "\n",
    "# rain_accuracies = list()\n",
    "# alidation_accuracies = list()\n",
    "\n",
    "# pre calculate length of dataloaders\n",
    "train_dataloader_length = len(train_dataloader)\n",
    "val_dataloader_length = len(val_dataloader)\n",
    "print(\"Training...\")\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    \n",
    "    # init losses for this epoch\n",
    "    train_loss, train_accuracy = 0.0,0.0\n",
    "    # train loop\n",
    "    for X_train, y_train in tqdm(train_dataloader):\n",
    "        # activate train mode, not batchNorm or Dropout for this model but convention\n",
    "        model.train()\n",
    "        \n",
    "        # to gpu if available\n",
    "        X_train = X_train.to(device)\n",
    "        y_train = y_train.to(device)\n",
    "        \n",
    "        # zeroing gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # prediction\n",
    "        pred = model(X_train)\n",
    "        \n",
    "        \n",
    "        # calculation of loss\n",
    "        loss = criterion(pred, y_train)\n",
    "        train_loss += loss\n",
    "        \n",
    "        acc = accuracy(pred, y_train)\n",
    "        train_accuracy+=acc\n",
    "        \n",
    "        # print(\"*******\")        \n",
    "        # backpropagation operation over loss\n",
    "        loss.backward()\n",
    "        \n",
    "        # update params according to optimizer algorithm and model parameters\n",
    "        optimizer.step()        \n",
    "    \n",
    "    # average loss and accuracy on batch\n",
    "    train_loss /= train_dataloader_length\n",
    "    train_accuracy /= train_dataloader_length\n",
    "        \n",
    "        \n",
    "    \n",
    "    # validation loop\n",
    "    validation_loss, validation_accuracy = 0.0,0.0\n",
    "    model.eval()\n",
    "    print(\"Validation...\")\n",
    "    with torch.inference_mode():\n",
    "        for X_validation, y_validation in tqdm(val_dataloader):\n",
    "        \n",
    "            # to gpu if available\n",
    "            X_validation = X_validation.to(device)\n",
    "            y_validation = y_validation.to(device)\n",
    "            \n",
    "            # prediction\n",
    "            pred = model(X_validation)\n",
    "            \n",
    "            # calculating loss for val\n",
    "            loss = criterion(pred, y_validation)\n",
    "            validation_loss += loss\n",
    "            \n",
    "            # calculate accuracy using lightning metrics and add for current epoch\n",
    "            acc = accuracy(pred, y_validation)\n",
    "            validation_accuracy+=acc\n",
    "            \n",
    "        # average loss and accuracy on batch\n",
    "        validation_loss/=val_dataloader_length\n",
    "        validation_accuracy/=val_dataloader_length\n",
    "        \n",
    "    # SummaryWriter for losses\n",
    "    summary_logger.add_scalars(\n",
    "        main_tag=\"Losses\",\n",
    "        tag_scalar_dict={\n",
    "            \"train/loss\": train_loss,\n",
    "            \"validation/loss\": validation_loss\n",
    "        },\n",
    "        global_step=epoch\n",
    "    )\n",
    "    # SummaryWriter for accuracies\n",
    "    summary_logger.add_scalars(\n",
    "        main_tag=\"Accuracies\",\n",
    "        tag_scalar_dict={\n",
    "            \"train/accuracy\": train_accuracy,\n",
    "            \"validation/accuracy\": validation_accuracy\n",
    "        },\n",
    "        global_step=epoch\n",
    "    )\n",
    "    \n",
    "    print(f\" Epoch: {epoch} -- Train Loss: {train_loss: .3f} -- Train Acc : {train_accuracy: .3f} -- Val Loss: {validation_loss: .3f} -- Val Acc: {validation_accuracy: .3f} \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 625/625 [00:07<00:00, 87.37it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Test Loss:  0.060 -- Test Acc :  0.985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# test \n",
    "\n",
    "\n",
    "\n",
    "test_dataloader_length = len(test_dataloader)\n",
    "\n",
    "model.eval()\n",
    "test_loss, test_accuracy = 0.0,0.0\n",
    "with torch.inference_mode():\n",
    "    for X_test, y_test in tqdm(test_dataloader):\n",
    "        \n",
    "        X_test = X_test.to(device) \n",
    "        y_test = y_test.to(device) \n",
    "        \n",
    "        # test prediction\n",
    "        pred = model(X_test)\n",
    "        \n",
    "        # calculating loss for test set\n",
    "        loss = criterion(pred, y_test)\n",
    "        test_loss += loss\n",
    "        \n",
    "        # calculate accuracy using lightning metrics and add for current epoch\n",
    "        acc = accuracy(pred, y_test)\n",
    "        test_accuracy+=acc\n",
    "\n",
    "        \n",
    "    # average loss and accuracy on batch\n",
    "    test_loss/=test_dataloader_length\n",
    "    test_accuracy/=test_dataloader_length\n",
    "    \n",
    "print(f\" Test Loss: {test_loss: .3f} -- Test Acc : {test_accuracy: .3f}\")\n",
    "\n",
    "# SummaryWriter for losses\n",
    "summary_logger.add_scalars(\n",
    "    main_tag=\"Losses\",\n",
    "    tag_scalar_dict={\n",
    "        \"test/loss\": test_loss,\n",
    "    },\n",
    "    global_step=epoch\n",
    ")\n",
    "\n",
    "# SummaryWriter for accuracies\n",
    "summary_logger.add_scalars(\n",
    "    main_tag=\"Accuracies\",\n",
    "    tag_scalar_dict={\n",
    "        \"test/accuracy\": test_accuracy\n",
    "    },\n",
    "    global_step=epoch\n",
    ")\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model:nn.Module, epochs: int, base_path: str, name: str):\n",
    "    torch.save(model, os.path.join(base_path, f\"{name}_{epochs}.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(model, epochs, \"models\", \"LeNet5_model_01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(torch.randint(0, 100, (1,1))[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X, test_y = iter(test_dataloader).__next__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 1, 28, 28])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-10.3349,   1.7753,  -6.6977,  -2.3191,  15.3755,  -2.7241,  -5.7152,\n",
      "           1.6385,  -1.7889,   4.9020],\n",
      "        [  2.6413,  -1.0144,   1.3535, -11.1045,   3.7988,   0.8837,  18.9129,\n",
      "          -4.9064,   2.4326,  -3.1384]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "tensor([4, 6])\n"
     ]
    }
   ],
   "source": [
    "out = model(test_X[:2].to(device))\n",
    "\n",
    "print(out)\n",
    "print(test_y[:2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6007 (pid 14136), started 0:00:07 ago. (Use '!kill 14136' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-f3b2e3eeaf9104d9\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-f3b2e3eeaf9104d9\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6007;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir={\"./experiments\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUCCESS: The process with PID 14136 has been terminated.\n"
     ]
    }
   ],
   "source": [
    "!taskkill /F /PID  14136"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Add Normalization"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
