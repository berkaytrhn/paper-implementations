{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms\n",
    "import torch.nn.functional as F\n",
    "\n",
    "composed_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Lambda(lambda x: F.pad(x, (2, 2, 2, 2), mode='constant', value=0)),  # Pad from 28x28 to 32x32\n",
    "])\n",
    "\n",
    "dataset = MNIST(\"./data/\", transform=composed_transforms, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 32, 32]) 5\n"
     ]
    },
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/wAALCAAgACABAREA/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/9oACAEBAAA/APn+gDJwOtXrbRNVvREbXTL2cTPsi8q3Zt7c8Lgcng8D0NV7q0ubG6ktbu3lt7iM7XimQo6H0IPIqGvaPg346sbW6tPDs2i6Ul00cgtr90CSTTZ3RozY7nIz9Pxw/F/xX8cXj2tnfCXRb20aQv8AZ1eEyBsAZB9MMMg85NecXFxNd3MlxcyvLNIxZ5HbLMT3JqKt7wv4R1/xXqCwaJZSyshBaf7qRehLdun1r1f4jx2Wm/DkaT4s1uz1jxfA6/Y5Ic+bFHlcq7AZIxvOWxnPrXhVWtOvF0/UILtrS2uxE27yLlS0b+zAEEj8a7jUvjP4svdK/syzNjpFnsEfl6bB5WFAxgEklfwI6V587tI5d2LMxySTkk0lf//Z",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAAAAABWESUoAAABAElEQVR4AWNgGImAWUhIqK5jvdSy/9/rIf5nQQSDHJuVjUAwiP9kUuDniwchMoxwBYZ7+aHsf0lfGZ69vwmXgTKEbv8FgWPbvn9El4LyA+Zk//17lptBexYOBQx8jLP+RqFLMiEJfPr/kSEFWQBJDsrk3vfXDVMUWUT548MFOQifIUtB2YEf/v4tl8QiARfS3fX37zRpOBcLQyD2z9/dWMSRhH7+/ekA5yLFBURML8SUheHaIbgCNIb6lKfA4P61DU0YxpUouguKjpN+MAFUWtzpKkj6WCD2wBRaDY7NwwGcqNqgPPM1j0C6v7Ryo0tDfREYyMBwffPfng/o8kODDwB15l6AaZKe2QAAAABJRU5ErkJggg==",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=32x32>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = iter(dataset).__next__()\n",
    "print(X.shape, y)\n",
    "transforms.ToPILImage()(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class LeNet5(nn.Module):\n",
    "    \n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.feature_extractor = nn.Sequential(\n",
    "            # Input -> (batch_size,1,32,32)\n",
    "            # Layer 1\n",
    "            nn.Conv2d(\n",
    "                in_channels=1, \n",
    "                out_channels=6,\n",
    "                kernel_size=5,\n",
    "                padding=2,\n",
    "                stride=1), # -> (batch_size,6,28,28)\n",
    "            nn.Tanh(),\n",
    "            nn.AvgPool2d(kernel_size=2, stride=2), # -> (batch_size,6,14,14)\n",
    "            \n",
    "            # Layer 2\n",
    "            nn.Conv2d(\n",
    "                in_channels=6,\n",
    "                out_channels=16,\n",
    "                kernel_size=5,\n",
    "                stride=1,\n",
    "                padding=0), # -> (batch_size,16,10,10)\n",
    "            nn.Tanh(),\n",
    "            nn.AvgPool2d(kernel_size=2, stride=2), # (batch_size,16,5,5)\n",
    "        )\n",
    "        self.fully_connected = nn.Sequential(\n",
    "            nn.Flatten(), # (batch_size,400)\n",
    "            nn.Linear(in_features=400, out_features=120), # (batch_size,401200)\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(in_features=120, out_features=84), # (batch_size,84)\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(in_features=84, out_features=10), # (batch_size,10)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.classifier(self.feature(x))\n",
    "    \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LeNet5(\n",
       "  (feature_extractor): Sequential(\n",
       "    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (1): Tanh()\n",
       "    (2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    (3): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (4): Tanh()\n",
       "    (5): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "  )\n",
       "  (fully_connected): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(in_features=400, out_features=120, bias=True)\n",
       "    (2): Tanh()\n",
       "    (3): Linear(in_features=120, out_features=84, bias=True)\n",
       "    (4): Tanh()\n",
       "    (5): Linear(in_features=84, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LeNet5()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
